---
title: "Ciencia de Datos üêß"
output-dir: docs
author:
  - Lic. Juan Isaula
format: 
  revealjs:
    multiplex: true
    footer: "[https://j-isaula.github.io/website_ji/](https://j-isaula.github.io/website_ji/)"
    theme: ["pp.scss"]
    slide-number: c/t
    incremental: false
    title-slide-attributes:
      data-background-image: img/penguin-highway.jpg
      data-background-size: cover 
editor: visual
---

```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)

```

## Historia de la IA

::::: columns
::: {.column style="font-size:28px"}
Al empezar con la programaci√≥n de ordenadores mediante algoritmos, en 1950 Alan Turin propone el `test de Turing,` el cual propone que si no puedes diferenciar entre conversar con un humano y una maquina, entonces, nos encontramos ante un nuevo concepto, algo interesante para su √©poca.
:::

::: column
![](img/Test_Turing.png)
:::
:::::

## Historia de la IA

::::: columns
::: {.column style="font-size:28px"}
-   Ante esto, McCarty en 1956 acu√±a el t√©rmino `Inteligencia Artificial` por primera vez en la historia.

-   Al siguiente a√±o, Rosenblat desarrolla Eliza, la primera red neuronal para un chatbot.
:::

::: column
![](img/ELIZA.png)
:::
:::::

## Historia de la IA

::::: columns
::: {.column style="font-size:25px"}
-   En 1996 Minsky crea el concepto de perceptrones, la arquitectura b√°sica empleada a d√≠a de hoy en redes neuronales, aunque debido a la limitaci√≥n computacional de la √©poca y que necesitaban muchos datos, su concepto queda en archivo, empezando un `inverno en la IA.`

-   En 1996 la IA renace gracias a Deep Blue, venciendo al campe√≥n mundial humano de ajedrez.
:::

::: column
![](img/Ajedrez.png)
:::
:::::

## Historia de la IA

::::: columns
::: {.column style="font-size:25px"}
-   En 2012, Google construyo un superordenador que aprende a reconocer caras de gatos y humanos y se empezo a popularizar `AlexNet` con resultados satisfactorios.

-   En 2014 por primera vez una IA supera el test de Turing, y Goodfellow crea el concepto de `GAN,` la primera IA que crea im√°genes por si misma.

-   En 2015 se supera al campe√≥n mundial humano de `Go`, un juego muy complicado.
:::

::: column
![](img/caras.png)
:::
:::::

## Historia de la IA

::::: columns
::: {.column style="font-size:25px"}
-   En 2017 Google crea una arquitectura que reduce la capacidad de memoria necesaria y aumenta el rendimiento de los modelos de redes neuronales, creando el concepto de `atention.`
-   En 2020 se crea la IA `Stable Diffusion,` revoluicionaria de los GAN, que permite crear imagenes con texto.
-   En 2022 OpenAI pone al p√∫blico el uso de ChatGPT, NVIDIA pone a la venta tarjetas gr√°ficas s√∫per potentes, empiezan a dar popularidad a las aplicaciones independientes de IA, etc...
:::

::: column
![](img/chatgpt.png)
:::
:::::

## Qu√© no es IA?

:::: columns
::: {.column style="font-size:25px"}
-   Calculadoras

-   Software o lenguages de programaci√≥n

-   Programaci√≥n de Reglas Espec√≠ficas

-   Sensores

-   Reconocer una figura geom√©trica en imagenes.

-   C√≥digos QR

`Nota: pero pueden tener IA`
:::
::::

## Qu√© si es IA?

:::: columns
::: {.column style="font-size:25px"}
-   Chatbot aut√≥nomo.
-   Voz a texto (y viceversa).
-   Asistentes virtuales (Alex, Siri, etc.)
-   Cualquier generador autom√°tico.(m√∫sica, im√°genes, res√∫menes, etc...)
-   Navegador inteligente, traductor.

`Nota: existen ocasiones en que una tarea parece sencilla, pero, tiene un modelo s√∫per complejo detras de lo que la hace sencilla.`
:::
::::

## Investigaci√≥n en IA

::::: columns
::: {.column style="font-size:25px"}
-   **Descubrimiento:** entrenar un modelo nunca antes entrenado.
-   **Te√≥rica:** algortimos, mejoras en rendimiento.
-   **Aplicada:** despliegues para terceros.
:::

::: column
![](img/Imagen%201.png)
:::
:::::

## Complicaciones en IA

::::: columns
::: {.column style="font-size:25px"}
-   Recolecci√≥n de datos.

-   Etiquetado de datos.

-   Sesgos (calidad de los datos: racismo, machismo, preferencias especificas, corrupci√≥n).

-   √âtica (protecci√≥n de datos, usos finales, externalidades dependen de IAs).

-   Velocidad de entrenamiento.

-   Velocidad de respuesta.

-   Explicabilidad.
:::

::: column
![](img/complicaciones.png)
:::
:::::

## Otros conceptos

:::: columns
::: column
![](img/otros.png)
:::
::::

## Etapas para el procesamiento de datos

:::::::: {.columns style="font-size:15px"}
::: {.column style="font-size:15px"}
**`OBTENER DATOS`**

Transformar de otros programas o lenguajes

Descargar de la web (web scraping)
:::

:::: {.columns style="font-size:15px"}
::: {.column style="font-size:15px"}
**`PROCESAR DATOS`**

Ordenar lo obtenido

Dar el formato requerido

Limpiar impurezas de las bases
:::
::::

::: {.column style="font-size:15px"}
**`ANALIZAR DATOS`**

Data Mining

Econometr√≠a

Machine Learning

Deep Learning
:::

::: {.column style="font-size:15px"}
**`REPORTAR DATOS`**

Crear reportes con gr√°ficos en una tabla en Exce, word o un dasboard.
:::
::::::::

## Aprendizaje Aut√≥matico (Machine Learning)

::::: columns
::: {.column style="font-size:25px"}
-   Conjunto de t√©cnicas que se emplean para crear IA.

-   Se clasifica en aprendizaje supervisado y no supervisado.

-   El supervisado se divide en: continuo, conteo, binario, multi clase, multi label

-   Su fin es predecir algo.
:::

::: column
![](img/ml.png)
:::
:::::

## Miner√≠a de datos

::::: columns
::: {.column style="font-size:30px"}
-   Este t√©rmino muchas veces lo confunden con machine learning y ciencia de datos.

-   Se refiere a la obtenci√≥n de nuevo conocimiento pr√°ctico gracias a los datos.

-   Su fin es explicar el por qu√© de algo.
:::

::: column
![](img/mineria.png)
:::
:::::

## Ciencia de datos

::::: columns
::: {.column style="font-size:25px"}
-   Es la aplicaci√≥n espec√≠ficada de IA a un campo de estudio, con el fin de aplicar teor√≠a o conocimiento a la IA, para que no sea tan `"no explicada".`

-   Normalmente se confunde con decirle IA m√°s a una profesi√≥n espec√≠ficada como medicina, marketing o telecomunicaciones, pero, esto aplica a cualquier carrera.

-   Su fin es aplicar el conocimiento para mejorar la predicci√≥n o el porqu√© de algo.
:::

::: column
![](img/cienciadatos.png)
:::
:::::

## Requisitos computacionales m√≠nimos para machine learning

:::: columns
::: {.column style="font-size:25px"}
8 GB de RAM

256 GB de SSD

4 n√∫cleos de procesamiento

Procesador Core i5

4 GB dedicados de GPU
:::
::::

## Con qu√© hacer IA / Ciencia de datos

::::: columns
::: {.column style="font-size:25px"}
-   Con cualquier lenguaje de programaci√≥n es posible, pero, principalmente se usan: `Python`, `Java`, `C++`, `Julia` y `Rub√≠.`
-   Como un lenguaje de programaci√≥n no tiene interfaz pre definida, se pueden instalar varias como `Spyder` o `Jupyter Notebooks`.
-   Como la IA son modelos matem√°ticos complejos, se puede emplear alternativamente Python en la nube de forma gratuita como `Google Colab` o `Kaggle.`
:::

::: {.column style="font-size:25px"}
-   Finalmente, si los recursos gratuitos no cubren tu demanda, puedes comprar m√°quinas potentes o pagar por su alquiler en la nube como `Google Cloud`, `AWS`, `Azure`, etc.
:::
:::::

## Recuerden

:::: columns
::: {.column style="font-size:25px"}
-   Un modelo no siempre ser√° el mejor al inicio, pero, para eso est√° la mejora continua.

-   Sean creativos al crear modelos.

-   Cualquier problema es aplicable.

-   Nunca descarten emplear modelos qua ya existen, as√≠ como nunca descarten hacer sus propios modelos.
:::
::::

## Preparaci√≥n y algoritmo para un buen modelo

:::: columns
::: {.column style="font-size:25px"}
-   A la variable por predecir $Y$ se le conoce como: dependiente, label, explicada, de inter√©s, output.

-   A la o las variables para predecir se le puede decir: independiente $(X)$, features, caracter√≠sticas, input.

-   Dataset: base de datos.
:::
::::

## Tipos de investigaci√≥n

:::::: columns
::: {.column style="font-size: 20px"}
**`Machine Learning`**

-   Busca predecir.

-   Usa muchas variables para explorar.

-   No es necesariamente explicable.

-   El producto es un modelo que genere outputs precisos.
:::

::: {.column style="font-size: 20px"}
**`Ciencia de Datos`**

-   Busca explicar y predecir.

-   Usa variables te√≥ricas y a veces adicionales.

-   Siempre busca explicar.

-   El producto es un modelo que tenga equilibrio entre lo que genera y lo que explica.
:::

::: {.column style="font-size: 20px"}
**`Miner√≠a de datos`**

-   Busca explicar y predecir.

-   Usa variables te√≥ricas y a veces adicionales.

-   Siempre busca explicar.

-   El producto es un modelo que tenga equilibrio entre lo que genera y lo que explica.
:::
::::::

## Recolecci√≥n de Dataset

::: {.columns style="font-size:20px"}
tener una idea de investigaci√≥n es el primer paso:

-   Puedo predecir si el precio de una acci√≥n subir√° ma√±ana ?

-   Puedo predecir si alguien me ama en base a nuestro chat?

-   Puedo crear un modelo para detectar armas en una foto?

`Pero`, sin un dataset nuestra idea nunca se podr√° producir.

![](img/dataset.png){width="252"}
:::

## Datos sin sesgo

::: {.columns style="font-size:20px"}
-   Un buen modelo depende de un buen dataset.

-   El modelo aprende lo que le ense√±amos, si le ense√±amos mal...

-   Debemos diferenciar entre patron y sesgo.

-   Ejemplos: ense√±ar brechas de g√©nero, especificaciones de raza a una carrera, etc.

![](img/sesgo.png){width="382"}
:::

## Etiquetas Correctas

::: {.columns style="font-size:20px"}
-   Existen estudios con una label sencilla, como etiquetar si una imagen es un gato o un perro, a que precio se vendi√≥ una casa.

-   Otros no lo son tan directos y puede ser hasta subjetivo, como etiquetar si un correo es spam, si un texto es ofensivo, si un registro es una anomal√≠a....

-   Importante considerar si necesitar√°s un experto en la materia o no para esta labor.

![](img/label.png){width="382"}
:::

## Estimaci√≥n de Modelos

::: {.columns style="font-size:20px"}
-   A partir de aqu√≠ si depende de nuestras habilidades.

-   **Verificar que no hayan missings y estandarizar variables.**

-   **TODOS** los modelos persiguen lo mismo, lo que se cambia es la forma de conseguirlo, pero, todos siguen lo siguiente:\
    $$Y_i = f(X_i)$$

-   Lo que cambia es $f(X_i)$ o la forma que lo consideramos

-   Entonces, probaremos varios modelos hasta encontrar un `ganador`.

-   El ganador se decide en base a `m√©tricas` que dependen de la variable dependiente y nuestro objetivo particular
:::

## Delimitando nuestra data

::: {.columns style="font-size:20px"}
-   Entrenamiento (`Train`): parte de mi data que me sirve para estimar el modelo.

-   Prueba (`test`): parte de mi data que sirve para validar el modelo.

-   Nueva data (`Wild`): la data que falta no tiene label y por ende debo predecir, y no sabr√© los resultados hasta que llegue el d√≠a de presentarse dicho escenario.

-   Frecuentemente se usa `Split`:\

    | **Tus datos (Conozco** $Y$**)** | **No tus datos (No conozco** $Y$**)** |
    |------------------------------------|------------------------------------|
    | Train (estimar modelo) \| Test (probar modelo) | Wild (probar modelo) |
    | Eficiencia conocida \| Eficiencia conocida | Eficiencia Desconocida |
:::

## Ajustes en Modelos

::: {.columns style="font-size:20px"}
-   **Underfitting** (`subajuste)`: no entren√© lo suficiente al modelo.

-   **Overfitting** (`sobreajuste`): entren√© demasiado al modelo y no hay posibilidad a nuevos casos.

-   **Balanced** (`balanceado`): entren√© lo suficiente al modelo y predice bien nueva data.

![](img/ajuste.png)
:::

## Consideraciones

::: {.columns style="font-size:20px"}
-   Lo anterior es como escoger un modelo, pero, recordar que tendr√°n un resultado diferente si var√≠an en:\
    -   La muestra (split)\
    -   Las features\
    -   Las transformaciones de features\
    -   Los hiperpar√°metros por calibrar
-   Aqu√≠ viene lo importante que es **`automatizar al programar`**.
:::

## Luego que gana un modelo?

::: {.columns style="font-size:20px"}
-   Se debe **`guardar los par√°metros`** en el formato que consideren, normalmente se usa `.pkl` para modelos con datos estructurados.

-   Luego de guardar, lo puedes pasar a un sistema o pagina web para que cuando algui√©n m√°s llene l**`os mismos inputs le retorne un output`**, y luego toca esperar que sea una buena predicci√≥n.

-   Recordar que la ganancia es que todo esto es autom√°tico y **`para grandes cantidades de datos`**.

-   Tambi√©n pueden venderlo.
:::

## Qu√© m√°s continuaras viendo aqu√≠?

::: {.columns style="font-size:20px"}
-   A partir de aqu√≠ sigue estudiar **`los tipos de variables dependientes.`**
-   Cada modelo, ventajas y desventajas.
-   Estudiar las m√©tricas pertinentes.
-   Aprender los tipos de calibraci√≥n.
-   Salir de los datos estructurados ( un Excel por as√≠ decirlo) e ir a textos, sonidos e im√°genes y volver a los primeros 4 puntos.
-   Luego de lo anterior, aprender sobre **`modelos m√°s complejos (Deep Learning)`** y repetir el punto 5.
:::

## Empezaremos a ciegas con...

::: {.columns style="font-size:20px"}
-   Se realizar√° tanto en local como Google Colab.
-   Un poco de estad√≠stica descriptiva.
-   Problema de aprendizaje supervisado con variable explicada continua.
-   Modelo de regresi√≥n lineal, support vector machine y √°rbol de decisi√≥n.
-   M√©trica de $R^2$ y $MSE$
-   Guardar y probar modelo.
:::

## Procesos

::: {.columns style="font-size:20px"}
-   Importar librer√≠as.
-   Cargar datos: `pd.read_excel()`
-   Limpiar....
-   Separar base: `train_test_split()`
-   Estimar modelo: model = `modelo().fit(x_train, y_train)`
-   Predecir: y_pred_test = `model.predict(X_test)`
-   Scores: `model.score(X_train, y_test) | mse(y_test, y_pred_test)`
:::

## Consideraciones al pasar a Colab

::: {.columns style="font-size:20px"}
-   Recuerden subir su archivo cada vez que inician sesi√≥n o tenerlo en Google Drive.
-   Borrar os.chdir() porque **no es su computadora**.
-   Colocar **`!pip install paquete`** si les genera error por falta de paquete.
-   Listo!
:::
